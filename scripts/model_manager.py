#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""AgentDoc æ¨¡å‹ç®¡ç†å·¥å…·

æä¾›æ¨¡å‹ä¸‹è½½ã€æµ‹è¯•ã€ç®¡ç†çš„ç»Ÿä¸€å‘½ä»¤è¡Œç•Œé¢ã€‚
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é¿å…ä¸æ ‡å‡†åº“queueæ¨¡å—å†²çª
if str(project_root) in sys.path:
    # ä¸´æ—¶ç§»é™¤å¯èƒ½å†²çªçš„è·¯å¾„
    temp_paths = [p for p in sys.path if 'queue' not in p]
    sys.path = temp_paths + [str(project_root)]

try:
    from models.downloader import ModelDownloader
    from models.test_models import ModelTester
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…")
    sys.exit(1)


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AgentDoc æ¨¡å‹ç®¡ç†å·¥å…·                      â•‘
â•‘                                                              â•‘
â•‘  æ”¯æŒ Qwen2.5 ç³»åˆ—æ¨¡å‹çš„ä¸‹è½½ã€æµ‹è¯•å’Œç®¡ç†                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


def cmd_list_models(args):
    """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹"""
    downloader = ModelDownloader()
    
    print("\nğŸ“‹ æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨:")
    print("=" * 80)
    
    for name, info in downloader.list_models().items():
        status = "âœ… å·²ä¸‹è½½" if downloader.is_model_downloaded(name) else "â¬œ æœªä¸‹è½½"
        print(f"\nğŸ¤– {name}")
        print(f"   å¤§å°: {info.size}")
        print(f"   çŠ¶æ€: {status}")
        print(f"   æè¿°: {info.description}")
        if downloader.is_model_downloaded(name):
            path = downloader.get_model_path(name)
            print(f"   è·¯å¾„: {path}")


def cmd_download_model(args):
    """ä¸‹è½½æ¨¡å‹"""
    if not args.model:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šæ¨¡å‹åç§° --model")
        return
    
    downloader = ModelDownloader()
    
    print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {args.model}")
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    model_info = downloader.get_model_info(args.model)
    if model_info:
        print(f"ğŸ“Š æ¨¡å‹å¤§å°: {model_info.size}")
        print(f"ğŸ“ æè¿°: {model_info.description}")
        print(f"ğŸ”— ä»“åº“: {model_info.repo_id}")
        
        if args.modelscope:
            print("ğŸŒ ä½¿ç”¨ ModelScope é•œåƒåŠ é€Ÿ")
        
        print("\nâ³ ä¸‹è½½ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    success = downloader.download_model(
        args.model,
        force=args.force,
        use_modelscope=args.modelscope
    )
    
    if success:
        print(f"\nâœ… æ¨¡å‹ {args.model} ä¸‹è½½æˆåŠŸ!")
        path = downloader.get_model_path(args.model)
        print(f"ğŸ“ ä¿å­˜è·¯å¾„: {path}")
    else:
        print(f"\nâŒ æ¨¡å‹ {args.model} ä¸‹è½½å¤±è´¥")


def cmd_test_model(args):
    """æµ‹è¯•æ¨¡å‹"""
    if not args.model:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šæ¨¡å‹åç§° --model")
        return
    
    tester = ModelTester()
    
    print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹: {args.model}")
    
    if args.quick:
        # å¿«é€Ÿæµ‹è¯•
        prompt = args.prompt or "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"
        result = tester.test_model_inference(args.model, prompt)
        
        print("\nğŸ“‹ å¿«é€Ÿæµ‹è¯•ç»“æœ:")
        print("-" * 50)
        print(f"ğŸ’¬ æç¤ºè¯: {result['prompt']}")
        print(f"âœ… æˆåŠŸ: {result['inference_success']}")
        
        if result['inference_success']:
            print(f"â±ï¸  æ¨ç†æ—¶é—´: {result['inference_time']:.2f}s")
            print(f"ğŸ’­ æ¨¡å‹å›å¤:\n{result['response']}")
        else:
            print(f"âŒ é”™è¯¯: {result['error']}")
    else:
        # å®Œæ•´æµ‹è¯•
        result = tester.run_full_test(args.model)
        
        print("\nğŸ“‹ å®Œæ•´æµ‹è¯•ç»“æœ:")
        print("-" * 50)
        
        # åŠ è½½æµ‹è¯•ç»“æœ
        load_result = result['load_result']
        print(f"ğŸ”„ æ¨¡å‹åŠ è½½: {'âœ… æˆåŠŸ' if load_result['load_success'] else 'âŒ å¤±è´¥'}")
        
        if load_result['load_success']:
            print(f"â±ï¸  åŠ è½½æ—¶é—´: {load_result['load_time']:.2f}s")
            model_info = load_result['model_info']
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {model_info['num_parameters']:,}")
            print(f"ğŸ–¥ï¸  è¿è¡Œè®¾å¤‡: {model_info['device']}")
            
            # æ¨ç†æµ‹è¯•ç»“æœ
            print("\nğŸ’­ æ¨ç†æµ‹è¯•:")
            for i, inf_result in enumerate(result['inference_results'], 1):
                status = "âœ…" if inf_result['inference_success'] else "âŒ"
                print(f"  {i}. {status} {inf_result['prompt'][:30]}...")
                if inf_result['inference_success']:
                    print(f"     â±ï¸ {inf_result['inference_time']:.2f}s")
                    print(f"     ğŸ’¬ {inf_result['response'][:60]}...")
        else:
            print(f"âŒ åŠ è½½é”™è¯¯: {load_result['error']}")


def cmd_remove_model(args):
    """åˆ é™¤æ¨¡å‹"""
    if not args.model:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šæ¨¡å‹åç§° --model")
        return
    
    downloader = ModelDownloader()
    
    if not downloader.is_model_downloaded(args.model):
        print(f"âš ï¸  æ¨¡å‹ {args.model} æœªä¸‹è½½")
        return
    
    # ç¡®è®¤åˆ é™¤
    if not args.force:
        response = input(f"\nâš ï¸  ç¡®å®šè¦åˆ é™¤æ¨¡å‹ {args.model} å—? (y/N): ")
        if response.lower() != 'y':
            print("âŒ å–æ¶ˆåˆ é™¤")
            return
    
    success = downloader.remove_model(args.model)
    if success:
        print(f"\nâœ… æ¨¡å‹ {args.model} åˆ é™¤æˆåŠŸ")
    else:
        print(f"\nâŒ æ¨¡å‹ {args.model} åˆ é™¤å¤±è´¥")


def cmd_status(args):
    """æ˜¾ç¤ºçŠ¶æ€"""
    downloader = ModelDownloader()
    
    print("\nğŸ“Š AgentDoc æ¨¡å‹çŠ¶æ€")
    print("=" * 50)
    
    # ä¸‹è½½ç›®å½•ä¿¡æ¯
    print(f"ğŸ“ ä¸‹è½½ç›®å½•: {downloader.download_dir}")
    
    # å·²ä¸‹è½½æ¨¡å‹
    downloaded = downloader.get_downloaded_models()
    print(f"\nğŸ“¦ å·²ä¸‹è½½æ¨¡å‹ ({len(downloaded)} ä¸ª):")
    
    if downloaded:
        total_size = 0
        for model in downloaded:
            path = downloader.get_model_path(model)
            try:
                # è®¡ç®—ç›®å½•å¤§å°
                size = sum(f.stat().st_size for f in path.rglob('*') if f.is_file())
                size_gb = size / (1024**3)
                total_size += size_gb
                print(f"  âœ… {model} ({size_gb:.1f} GB)")
            except:
                print(f"  âœ… {model} (å¤§å°æœªçŸ¥)")
        
        print(f"\nğŸ’¾ æ€»å ç”¨ç©ºé—´: {total_size:.1f} GB")
    else:
        print("  (æš‚æ— )")
    
    # å¯ç”¨æ¨¡å‹
    all_models = downloader.list_models()
    available = len(all_models) - len(downloaded)
    print(f"\nğŸ”„ å¯ä¸‹è½½æ¨¡å‹: {available} ä¸ª")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="AgentDoc æ¨¡å‹ç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s list                          # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
  %(prog)s download -m qwen2.5-7b-instruct  # ä¸‹è½½æ¨¡å‹
  %(prog)s test -m qwen2.5-7b-instruct      # æµ‹è¯•æ¨¡å‹
  %(prog)s test -m qwen2.5-7b-instruct --quick  # å¿«é€Ÿæµ‹è¯•
  %(prog)s status                        # æŸ¥çœ‹çŠ¶æ€
  %(prog)s remove -m qwen2.5-7b-instruct    # åˆ é™¤æ¨¡å‹
"""
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # list å‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹')
    
    # download å‘½ä»¤
    download_parser = subparsers.add_parser('download', help='ä¸‹è½½æ¨¡å‹')
    download_parser.add_argument('--model', '-m', required=True, help='æ¨¡å‹åç§°')
    download_parser.add_argument('--force', '-f', action='store_true', help='å¼ºåˆ¶é‡æ–°ä¸‹è½½')
    download_parser.add_argument('--modelscope', action='store_true', help='ä½¿ç”¨ModelScopeé•œåƒ')
    
    # test å‘½ä»¤
    test_parser = subparsers.add_parser('test', help='æµ‹è¯•æ¨¡å‹')
    test_parser.add_argument('--model', '-m', required=True, help='æ¨¡å‹åç§°')
    test_parser.add_argument('--quick', '-q', action='store_true', help='å¿«é€Ÿæµ‹è¯•')
    test_parser.add_argument('--prompt', '-p', help='è‡ªå®šä¹‰æµ‹è¯•æç¤ºè¯')
    
    # remove å‘½ä»¤
    remove_parser = subparsers.add_parser('remove', help='åˆ é™¤æ¨¡å‹')
    remove_parser.add_argument('--model', '-m', required=True, help='æ¨¡å‹åç§°')
    remove_parser.add_argument('--force', '-f', action='store_true', help='å¼ºåˆ¶åˆ é™¤ï¼Œä¸è¯¢é—®')
    
    # status å‘½ä»¤
    status_parser = subparsers.add_parser('status', help='æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºæ¨ªå¹…
    print_banner()
    
    # æ‰§è¡Œå‘½ä»¤
    if args.command == 'list':
        cmd_list_models(args)
    elif args.command == 'download':
        cmd_download_model(args)
    elif args.command == 'test':
        cmd_test_model(args)
    elif args.command == 'remove':
        cmd_remove_model(args)
    elif args.command == 'status':
        cmd_status(args)
    else:
        parser.print_help()


if __name__ == '__main__':
    main()